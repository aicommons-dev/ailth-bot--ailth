{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "AILTH_BOT.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicommons-dev/ailth-bot--ailth/blob/master/AILTH_BOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVJ7vtWgNH9h",
        "colab_type": "text"
      },
      "source": [
        "# A SIMPLE RETRIEVAL BASED CHATBOT\n",
        "A Retrieval based bot - using cosine similarity between words entered by the user and the words in the corpus.\n",
        "We 'll define a function response which searches the user’s utterance for one or more known keywords and returns one of several possible responses. If it doesn’t find the input matching any of the keywords, it returns a response:” I am so sorry! I dont understand your words\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9zNUgGZNH9i",
        "colab_type": "text"
      },
      "source": [
        "### IMPORT NECCESSARY LIBRARIES OR DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9AJ6UZhNH9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # - Linear Algebra\n",
        "import random # - Random values/strings\n",
        "import nltk # - Natural languagua processing toolkit for Natural language preprocesing\n",
        "import string # - To process standard python strings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #convert a collection of raw text to a matrix of TF-IDF features\n",
        "from sklearn.metrics.pairwise import cosine_similarity #used to find the similarity between words/values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZm3h5xGNH9o",
        "colab_type": "text"
      },
      "source": [
        "### READ TEXT DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06-IcfiONH9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Text =open('HEALTH INFORMATION.txt','r',errors = 'ignore') #Assign a variable to text path where the file is located\n",
        "Text =Text.read() #Read the path of the assigned variable and store in a new variable for preprocessing usage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFd0OrEiNH9t",
        "colab_type": "text"
      },
      "source": [
        "### TEXT PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYicrvxgNH9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Text = Text.lower()# converts all text to lowercase; this help to avoid different meaning/pattern within text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxkuttXcNH9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDt4AmBNH91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_tokens = nltk.sent_tokenize(Text)# converts a text file to list of sentences \n",
        "word_tokens = nltk.word_tokenize(Text)# converts a text file to list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k_OX9p0NH95",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e7d735e-3ae5-44bd-e660-742be04f126e"
      },
      "source": [
        "#preview tokenized sentence example\n",
        "sentence_tokens[:2] #Output the first 2 tokenized sentenced, you can tune to 1 and see how it works"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffmuch of the weight that you gain during pregnancy is not fat, but is related to the baby.',\n",
              " 'growth of the fetus, the placenta, maternal blood volume, maternal fat stores, and tissues all contribute to weight gain during pregnancy.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXLhVPIdNH9_",
        "colab_type": "code",
        "colab": {},
        "outputId": "473a6239-09ba-4608-9a86-14c2ea3603f5"
      },
      "source": [
        "#preview tokenized word example\n",
        "word_tokens[:5] #Output the first 5 tokenized word, you can tune to see how it works"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffmuch', 'of', 'the', 'weight', 'that']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhjXahTnNH-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "##WordNet is a semantically-oriented dictionary of English included in NLTK."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA4U7HwCNH-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a fxn to lemmatize the tokenized words\n",
        "def LemTokens(tokens):\n",
        "    lemmatized = [lemmer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4NEbRVMNH-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Store punctuations removal from words into a variable\n",
        "remove_punctuations = dict((ord(punctuations), None) for punctuations in string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvquqhDYNH-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a fxn to Normalized lemmatized words i.e remove puctuations and convert all text to lower case \n",
        "def LemNormalize(text):\n",
        "    NormalizedLemmatized = LemTokens(nltk.word_tokenize(text.lower().translate(remove_punctuations)))\n",
        "    return  NormalizedLemmatized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJSAGhfkNH-S",
        "colab_type": "text"
      },
      "source": [
        "### SIMPLE KEYWORD MATCHING\n",
        "Next,Define a fxn for a greeting by the AXABot i.e if a user’s input is a greeting, the bot respond with a greeting response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC8PI0KqNH-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"what's up\",\"hey\")\n",
        "GREETING_RESPONSES = [\"i am here to attend to you\", \"hey\", \"how can i help you*\", \"what would you like to know health status\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbrdtICNH-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOB6nd57NH-Z",
        "colab_type": "text"
      },
      "source": [
        "### Generating Response\n",
        "To generate a response from our bot for input questions, the concept of document similarity will be used. So functionality of the modules imported above will be utilizied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pop2S0GNH-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sentence_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am so sorry! I dont understand your words\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sentence_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZdpWGlCNH-e",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will feed the lines that we want our bot to say while starting and ending a conversation depending upon the user’s input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ifKAv_5cNH-e",
        "colab_type": "code",
        "colab": {},
        "outputId": "976c7074-0add-4f2c-b0fc-b3474a0c358f"
      },
      "source": [
        "flag=True\n",
        "#welcome message\n",
        "print(\"Welcome: I am AILTH BOT. I will give you personalized health and nutrition tips. If you want to exit the conversion, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input() #allows user input\n",
        "    user_response=user_response.lower() #convert user response to lower case for the botb\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' or user_response=='okay'):\n",
        "            flag=False\n",
        "            print(\"AILTH BOT: You are welcome..\")\n",
        "        elif(greeting(user_response)!=None):\n",
        "            print(\"AILTH BOT: \"+greeting(user_response))\n",
        "        else:\n",
        "            print(\"AILTH BOT: \",end=\"\")\n",
        "            print(response(user_response))\n",
        "            sentence_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"AILTH BOT: Thanks\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome: I am AILTH BOT. I will give you personalized health and nutrition tips. If you want to exit the conversion, type Bye!\n",
            "Weight during pregnancy \n",
            "AILTH BOT: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the higher a woman’s weight is before pregnancy, the lower the amount of weight she needs to gain during pregnancy to deliver a healthy-sized baby.\n",
            "I want to loose weight\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AILTH BOT: the higher a woman’s weight is before pregnancy, the lower the amount of weight she needs to gain during pregnancy to deliver a healthy-sized baby.\n",
            "How can I loose weight during pregnancy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AILTH BOT: the higher a woman’s weight is before pregnancy, the lower the amount of weight she needs to gain during pregnancy to deliver a healthy-sized baby.\n",
            "How much weight should I gain during pregnancy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AILTH BOT: the higher a woman’s weight is before pregnancy, the lower the amount of weight she needs to gain during pregnancy to deliver a healthy-sized baby.\n",
            "When does pregnancy weight become excessive?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AILTH BOT: the higher a woman’s weight is before pregnancy, the lower the amount of weight she needs to gain during pregnancy to deliver a healthy-sized baby.\n",
            "How can I estimate fetal age?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/lawrence/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AILTH BOT: the amount of weight a woman gains, especially during the second and third trimesters, is an important indicator of fetal growth.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_DRM7MWNH-i",
        "colab_type": "text"
      },
      "source": [
        "# Feel free to contibute and make it better"
      ]
    }
  ]
}